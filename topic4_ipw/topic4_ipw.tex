%Input preamble
\input{preamble}
\let\counterwithout\relax
\let\counterwithin\relax
\definecolor{maroon}{HTML}{4B0082}

\begin{document}
%\onehalfspacing

\noindent \textbf{Inverse-Probability Weighting.}\\
\noindent Jorge Luis Garc√≠a \\
\noindent e-mail: jlgarci@clemson.edu\\

\noindent \textbf{Common Support.} The common support assumption is
\begin{align}
	0 & < \Pr \left( D_i | \bm{x}_i = \bm{x} \right) \nonumber \\
	  & =: p \left( \bm{x} \right) \nonumber \\
	  & < 1 \text{ for all } \bm{x} \in \supp \left( \bm{x}_i \right). 
\end{align}

\noindent The common support assumption is testable.\\

\noindent \textbf{Conditional Independence Assumption.} The conditional-independence assumption grants identification: 
\begin{align}
	\textbf{CIA}: \left( y_i^1, y_i^0 \right) \independent D_i \mid \bm{x}_i \nonumber 
\end{align}
\noindent which implies that
\begin{align}
	F \left( y_i^d \mid D_i = 1, \bm{x}_i \right) & = F \left( y_i^d \mid D_i =0, \bm{x}_i \right) \nonumber \\
	& = F \left( y_i^d \mid \bm{x}_i \right) \text{ for } d = 0,1. 
\end{align}

\noindent The sample model for the counterfactual outcomes is
\begin{align}
	y_i^0 = g^0 \left( \bm{x}_i \right) + e_i^0 \nonumber \\
	y_i^1 = g^1 \left( \bm{x}_i \right) + e_i^1.
\end{align}

\noindent \textbf{Estimators of the ATE, ATT, and ATU.} Under the CIA, two options for obtaining the estimates are the following: 
\begin{enumerate}
	\item Categorize $i \in \mathcal{I}$ into $J$ categories indexed by $\mathcal{J}$. The categories are based on the values of $\bm{x}_i$. Then, form the average difference between the subsample for which $D_i = 1$ and the subsample for which $D_i = 0$ for the category $j \in \mathcal{J}$: 
	\begin{align}
		\hat{\Delta}_j = \bar{y}_{1,j} - \bar{y}_{0,j}
	\end{align}
To form the ATE, ATT, and ATU estimators, average across categories: 
\begin{align}
	\hat{\Delta} = \sum \limits _{j \in \mathcal{J}} \omega_j \cdot \hat{\Delta}_j, 
\end{align}
\noindent where the category weights $\omega_j$ define the estimator of interest.
	\item Alternatively, $\Delta$ could be estimated from the regression 
\begin{align}
	y_i = \alpha + \Delta D_i + e_i, 
\end{align}
\noindent using the proper weights (recall the results from grouped regression). Note that this is unlikely to be the same as an unweighted regression (which would not acknowledge heterogeneity across categories). 
\end{enumerate}

\noindent The two options are numerically equivalent. The question is: What are the weights? Ideally, the weights are such that 
\begin{align}
	F \left( \bm{x}_i = \bm{x}_j \mid D_i = 0 \right) = F \left( \bm{x}_i = \bm{x}_j \mid D_i = 1 \right) \text{ for all } j \in \mathcal{J}
\end{align}
\noindent The weights make the distribution of the observed characteristics the exact same across the realizations of $D_i$. Thus, the average difference in $y_i$ for each $j \in \mathcal{J}$ is due to $D_i$ (under the CIA).\\

\noindent Note that these procedures are non-parametric in that they do not require specifying $g^0$ or $g^1$. If the CIA does not hold, the procedures at least enable estimating non-parametric estimates of the average difference between subsamples ($D_i = 0$ and $D_i = 1$).\\ 

\noindent So what are the weights? \\

\noindent Define 
\begin{align}
	\Pr \left( D_i = 1 \mid \bm{x}_i = \bm{x}_j \right) & =: p \left( \bm{x}_j \right) \nonumber \\ 
	& = \frac{n_{1j}}{n_{0j} + n_{1j}}  
\end{align}
\noindent where $n_{dj}$ is the number of individuals in category $j \in \mathcal{J}$ for whom $D_i = d$. 

\noindent The weights for each estimator are:
\begin{align}
	\begin{array}{lcc}
		& \text{Observations with $D_i = 1$} & \text{Observations with $D_i = 0$} \\
		& & \\
	\text{     ATE     } & \frac{ 1 } { p \left( \bm{x}_j \right) } & \frac{ 1 } { 1 - p \left( \bm{x}_j \right) } \\
	    & & \\
	\text{     ATT     } & 1 & \frac{ p \left( \bm{x}_j \right) } { 1 - p \left( \bm{x}_j \right) } \\
		& & \\
	\text{     ATU     } & \frac{ 1 - p \left( \bm{x}_j \right) } { p \left( \bm{x}_j \right) } & 1 \\
	\end{array}
\end{align}


\end{document}
